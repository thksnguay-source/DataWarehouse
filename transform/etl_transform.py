import json
import re
from datetime import datetime
import pandas as pd
from sqlalchemy import create_engine, text

# ============================================
# MYSQL CONNECTION
# ============================================
def get_mysql_url():
    return "mysql+pymysql://root:@localhost:3306/datawarehouse?charset=utf8mb4"

def create_mysql_engine():
    return create_engine(get_mysql_url(), pool_pre_ping=True)

# ============================================
# ETL LOG FUNCTIONS
# ============================================
def start_etl_log():
    engine = create_mysql_engine()
    batch_id = f"batch_{datetime.now().strftime('%Y%m%d%H%M%S')}"
    try:
        with engine.begin() as conn:
            # T·∫°o b·∫£ng etl_log n·∫øu ch∆∞a c√≥ (theo c·∫•u tr√∫c th·ª±c t·∫ø)
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS etl_log (
                    etl_id INT AUTO_INCREMENT PRIMARY KEY,
                    batch_id VARCHAR(50) NOT NULL,
                    source_table VARCHAR(50) NOT NULL DEFAULT '',
                    target_table VARCHAR(50) NOT NULL DEFAULT '',
                    records_inserted INT DEFAULT 0,
                    records_updated INT DEFAULT 0,
                    records_skipped INT DEFAULT 0,
                    status ENUM('running','success','failed') DEFAULT 'running',
                    start_time TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
                    end_time TIMESTAMP NULL DEFAULT NULL
                )
            """))
            conn.execute(text("""
                INSERT INTO etl_log (batch_id, source_table, target_table, status) 
                VALUES (:batch_id, 'general', 'stg_products,dim_product', 'running')
            """), {"batch_id": batch_id})
            res_id = conn.execute(text("SELECT LAST_INSERT_ID()")).scalar()
        print(f" B·∫Øt ƒë·∫ßu ETL batch: {batch_id} (ID: {res_id})")
        return res_id, batch_id
    except Exception as e:
        print(f" Kh√¥ng th·ªÉ ghi log: {e}")
        return None, batch_id

def update_error_log(etl_id, error_msg):
    if not etl_id:
        return
    engine = create_mysql_engine()
    with engine.begin() as conn:
        # B·∫£ng etl_log kh√¥ng c√≥ c·ªôt error_msg, ch·ªâ c·∫≠p nh·∫≠t status
        conn.execute(text("""
            UPDATE etl_log
            SET status='failed',
                end_time=NOW()
            WHERE etl_id = :id
        """), {"id": etl_id})
        # In th√¥ng b√°o l·ªói ra console
        print(f"   ‚ö†Ô∏è  L·ªói ETL: {str(error_msg)[:200]}")

def update_success_log(etl_id, inserted_count):
    if not etl_id:
        return
    engine = create_mysql_engine()
    with engine.begin() as conn:
        conn.execute(text("""
            UPDATE etl_log
            SET status='success',
                records_inserted=:cnt,
                end_time=NOW()
            WHERE etl_id = :id
        """), {"cnt": inserted_count, "id": etl_id})
    print(f" ƒê√£ c·∫≠p nh·∫≠t Log: Success (Inserted: {inserted_count})")

# ============================================
# EXTRACT
# ============================================
def extract_from_general():
    print("\n" + "="*60)
    print("B∆Ø·ªöC 1: EXTRACT - ƒê·ªçc d·ªØ li·ªáu t·ª´ b·∫£ng general")
    print("="*60)
    engine = create_mysql_engine()
    try:
        query = "SELECT * FROM general"
        df = pd.read_sql(query, engine)
        print(f" ƒê√£ ƒë·ªçc {len(df)} d√≤ng t·ª´ b·∫£ng general")
        return df
    except Exception as e:
        print(f" L·ªói khi ƒë·ªçc d·ªØ li·ªáu: {e}")
        raise

# ============================================
# TRANSFORM
# ============================================
def transform_data(df):
    print("\n" + "="*60)
    print("B∆Ø·ªöC 2: TRANSFORM - L√†m s·∫°ch v√† chu·∫©n h√≥a d·ªØ li·ªáu")
    print("="*60)
    df = df.copy()

    # L·ªçc d·ªØ li·ªáu r√°c
    initial_count = len(df)
    df = df.dropna(subset=['T√™n s·∫£n ph·∫©m'])
    df = df[df['T√™n s·∫£n ph·∫©m'] != 'Kh√¥ng t√¨m th·∫•y']
    df = df[df['T√™n s·∫£n ph·∫©m'].astype(str).str.strip() != '']
    print(f" üîç Lo·∫°i b·ªè {initial_count - len(df)} d√≤ng d·ªØ li·ªáu r√°c")

    # Rename c√°c c·ªôt ch√≠nh sang snake_case
    df.rename(columns={
        'T√™n s·∫£n ph·∫©m': 'ten_san_pham',
        'Gi√°': 'sale_price_vnd',
        'Ngu·ªìn': 'nguon'
    }, inplace=True)

    # Tr√≠ch xu·∫•t Brand t·ª´ t√™n s·∫£n ph·∫©m
    brands_dict = {
        'IPHONE': 'Apple',
        'SAMSUNG': 'Samsung',
        'XIAOMI': 'Xiaomi',
        'OPPO': 'Oppo',
        'REALME': 'Realme',
        'VIVO': 'Vivo',
        'NOKIA': 'Nokia',
        'TECNO': 'Tecno',
        'HONOR': 'Honor',
        'SONY': 'Sony',
        'ASUS': 'Asus',
        'INFINIX': 'Infinix',
        'POCO': 'Xiaomi',
        'NOTHING': 'Nothing',
        'NUBIA': 'Nubia',
        'GOOGLE': 'Google',
        'VSMART': 'Vsmart'
    }
    
    def extract_brand(name):
        if pd.isna(name) or name == 'nan' or str(name).strip() == '':
            return 'Other'
        n = str(name).upper()
        for k, v in brands_dict.items():
            if k in n:
                return v
        return 'Other'
    
    df['brand'] = df['ten_san_pham'].apply(extract_brand)

    # Ph√¢n lo·∫°i Category
    def categorize(name):
        if pd.isna(name) or name == 'nan' or str(name).strip() == '':
            return 'Smartphone'
        n = str(name).upper()
        if any(x in n for x in ['FOLD', 'FLIP', 'GALAXY Z']):
            return 'Foldable'
        if 'TAB' in n or 'IPAD' in n:
            return 'Tablet'
        return 'Smartphone'
    
    df['category'] = df['ten_san_pham'].apply(categorize)

    # Metadata - Th√™m th√¥ng tin ng√†y crawl (DATETIME)
    df['ngay_crawl'] = datetime.now()
    df['date_key'] = datetime.now().strftime("%Y%m%d")
    
    # X·ª≠ l√Ω ngu·ªìn d·ªØ li·ªáu (VARCHAR)
    df['nguon'] = df['nguon'].fillna('CellphoneS')
    df['nguon'] = df['nguon'].astype(str).str.strip()

    # X·ª≠ l√Ω gi√° - gi·ªØ nguy√™n format TEXT (v√¨ c√≥ k√Ω t·ª± ƒë·∫∑c bi·ªát ‚Ç´, ƒë)
    df['sale_price_vnd'] = df['sale_price_vnd'].astype(str)
    df['sale_price_vnd'] = df['sale_price_vnd'].replace('nan', None)
    df['sale_price_vnd'] = df['sale_price_vnd'].replace('None', None)

    # ============================================
    # CHUY·ªÇN ƒê·ªîI KI·ªÇU D·ªÆ LI·ªÜU CHO C√ÅC C·ªòT
    # ============================================
    
    # X·ª≠ l√Ω t·∫•t c·∫£ c√°c c·ªôt text - chuy·ªÉn sang string v√† x·ª≠ l√Ω NULL
    # Gi·ªØ nguy√™n format text nh∆∞ng chu·∫©n b·ªã ƒë·ªÉ chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu trong SQL
    for col in df.columns:
        if col not in ['brand', 'category', 'ngay_crawl', 'date_key']:
            # Chuy·ªÉn sang string nh∆∞ng gi·ªØ NULL values
            df[col] = df[col].astype(str)
            # Thay th·∫ø 'nan' v√† 'None' th√†nh None (NULL trong SQL)
            df[col] = df[col].replace(['nan', 'None', 'NaT', '<NA>'], None)
            # X·ª≠ l√Ω c√°c gi√° tr·ªã r·ªóng
            df[col] = df[col].apply(lambda x: None if str(x).strip() in ['', 'nan', 'None', 'NaT', '<NA>'] else x)

    # Lo·∫°i b·ªè c·ªôt kh√¥ng c·∫ßn thi·∫øt (id v√† created_at kh√¥ng c√≥ trong stg_products)
    for col in ['id', 'created_at']:
        if col in df.columns:
            df.drop(columns=[col], inplace=True)

    # ƒê·∫£m b·∫£o th·ª© t·ª± c·ªôt ƒë√∫ng v·ªõi stg_products (URL ƒë·∫ßu ti√™n)
    if 'URL' in df.columns:
        cols = ['URL'] + [c for c in df.columns if c != 'URL']
        df = df[cols]

    print(f" ‚úÖ D·ªØ li·ªáu ƒë√£ l√†m s·∫°ch. T·ªïng d√≤ng: {len(df)}")
    print(f" üìä S·ªë c·ªôt sau transform: {len(df.columns)}")
    print(f" üìã C√°c c·ªôt: {', '.join(df.columns[:5])}... (t·ªïng {len(df.columns)} c·ªôt)")
    return df

# ============================================
# LOAD TO STAGING
# ============================================
def load_to_staging(df):
    print("\n" + "="*60)
    print("B∆Ø·ªöC 3: LOAD - N·∫°p d·ªØ li·ªáu v√†o stg_products")
    print("="*60)
    engine = create_mysql_engine()
    try:
        # S·ª≠ d·ª•ng pandas to_sql ƒë·ªÉ load d·ªØ li·ªáu
        df_to_load = df.copy()
        
        # ƒê·∫£m b·∫£o ngay_crawl l√† datetime object ƒë·ªÉ pandas t·ª± ƒë·ªông detect
        if 'ngay_crawl' in df_to_load.columns:
            df_to_load['ngay_crawl'] = pd.to_datetime(df_to_load['ngay_crawl'], errors='coerce')
        
        # Load v√†o staging (pandas s·∫Ω t·ª± ƒë·ªông t·∫°o b·∫£ng v·ªõi ki·ªÉu d·ªØ li·ªáu TEXT)
        df_to_load.to_sql('stg_products', engine, if_exists='replace', index=False, chunksize=1000)
        
        # C·∫≠p nh·∫≠t ki·ªÉu d·ªØ li·ªáu sau khi load (ALTER TABLE)
        print(" üîÑ ƒêang chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu...")
        with engine.begin() as conn:
            # C·∫≠p nh·∫≠t ngay_crawl th√†nh DATETIME
            if 'ngay_crawl' in df.columns:
                try:
                    conn.execute(text("""
                        ALTER TABLE stg_products 
                        MODIFY COLUMN ngay_crawl DATETIME NULL
                    """))
                    print("   ‚úì ngay_crawl -> DATETIME")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ chuy·ªÉn ngay_crawl sang DATETIME: {e}")
            
            # C·∫≠p nh·∫≠t c√°c c·ªôt VARCHAR (text ng·∫Øn)
            varchar_updates = {
                'nguon': 'VARCHAR(100)',
                'brand': 'VARCHAR(50)',
                'category': 'VARCHAR(50)',
                'date_key': 'VARCHAR(8)',
                'sale_price_vnd': 'VARCHAR(50)',
                'ten_san_pham': 'VARCHAR(255)',
                'C√¥ng ngh·ªá NFC': 'VARCHAR(10)',
                'H·ªó tr·ª£ m·∫°ng': 'VARCHAR(10)',
                'C·ªïng s·∫°c': 'VARCHAR(20)',
                'H·ªá ƒëi·ªÅu h√†nh': 'VARCHAR(50)',
                'Ch·ªâ s·ªë kh√°ng n∆∞·ªõc, b·ª•i': 'VARCHAR(10)',
                'C·∫£m bi·∫øn v√¢n tay': 'VARCHAR(50)',
                'Wi-Fi': 'VARCHAR(20)',
                'Bluetooth': 'VARCHAR(10)',
                'Th·∫ª SIM': 'VARCHAR(50)',
                'Lo·∫°i CPU': 'VARCHAR(50)'
            }
            
            for col, dtype in varchar_updates.items():
                if col in df.columns:
                    try:
                        # S·ª≠ d·ª•ng backtick cho t√™n c·ªôt c√≥ d·∫•u c√°ch ho·∫∑c k√Ω t·ª± ƒë·∫∑c bi·ªát
                        col_name = f"`{col}`" if ' ' in col or '-' in col else col
                        conn.execute(text(f"""
                            ALTER TABLE stg_products 
                            MODIFY COLUMN {col_name} {dtype} NULL
                        """))
                        print(f"   ‚úì {col} -> {dtype}")
                    except Exception as e:
                        print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ chuy·ªÉn {col} sang {dtype}: {e}")
            
            # C√°c c·ªôt c√≤n l·∫°i gi·ªØ nguy√™n TEXT (URL, m√¥ t·∫£ d√†i, th√¥ng s·ªë k·ªπ thu·∫≠t)
            print("   ‚úì C√°c c·ªôt kh√°c gi·ªØ nguy√™n TEXT")
        
        print(f" ‚úÖ ƒê√£ load {len(df)} d√≤ng v√†o b·∫£ng 'stg_products' v·ªõi ki·ªÉu d·ªØ li·ªáu ph√π h·ª£p")
        return len(df)
    except Exception as e:
        print(f" ‚ùå L·ªói load v√†o staging: {e}")
        raise

# ============================================
# LOAD TO DIMENSION TABLE
# ============================================
def load_to_dim():
    print("\n" + "="*60)
    print("B∆Ø·ªöC 4: LOAD - N·∫°p d·ªØ li·ªáu v√†o dim_product")
    print("="*60)
    engine = create_mysql_engine()
    
    with engine.begin() as conn:
        # L·∫•y danh s√°ch t·∫•t c·∫£ c√°c c·ªôt t·ª´ stg_products
        result = conn.execute(text("""
            SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH
            FROM INFORMATION_SCHEMA.COLUMNS
            WHERE TABLE_SCHEMA = 'datawarehouse' 
            AND TABLE_NAME = 'stg_products'
            ORDER BY ORDINAL_POSITION
        """))
        
        columns_info = result.fetchall()
        if not columns_info:
            print(" ‚ùå Kh√¥ng t√¨m th·∫•y b·∫£ng stg_products")
            return 0
        
        # X√¢y d·ª±ng c√¢u l·ªánh CREATE TABLE v·ªõi t·∫•t c·∫£ c√°c c·ªôt t·ª´ stg_products
        # Th√™m product_id l√†m PRIMARY KEY
        column_definitions = ["product_id INT AUTO_INCREMENT PRIMARY KEY"]
        
        for col_name, data_type, max_length in columns_info:
            # Lu√¥n escape t√™n c·ªôt v·ªõi backtick ƒë·ªÉ tr√°nh l·ªói v·ªõi t√™n ƒë·∫∑c bi·ªát
            col_name_escaped = f"`{col_name}`"
            
            # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu ph√π h·ª£p
            if data_type == 'text':
                col_def = f"{col_name_escaped} TEXT"
            elif data_type == 'varchar':
                length = f"({max_length})" if max_length else "(255)"
                col_def = f"{col_name_escaped} VARCHAR{length}"
            elif data_type == 'datetime':
                col_def = f"{col_name_escaped} DATETIME"
            elif data_type == 'int':
                col_def = f"{col_name_escaped} INT"
            elif data_type == 'decimal':
                col_def = f"{col_name_escaped} DECIMAL(10,2)"
            else:
                col_def = f"{col_name_escaped} {data_type.upper()}"
            
            column_definitions.append(col_def)
        
        # Drop v√† t·∫°o l·∫°i b·∫£ng ƒë·ªÉ ƒë·∫£m b·∫£o c·∫•u tr√∫c ƒë√∫ng
        # (V√¨ CREATE TABLE IF NOT EXISTS kh√¥ng thay ƒë·ªïi c·∫•u tr√∫c n·∫øu b·∫£ng ƒë√£ t·ªìn t·∫°i)
        conn.execute(text("DROP TABLE IF EXISTS dim_product"))
        
        # T·∫°o b·∫£ng dim_product v·ªõi t·∫•t c·∫£ c√°c c·ªôt gi·ªëng stg_products
        create_table_sql = f"""
            CREATE TABLE dim_product (
                {', '.join(column_definitions)}
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci
        """
        
        conn.execute(text(create_table_sql))
        print("   ‚úì ƒê√£ t·∫°o b·∫£ng dim_product v·ªõi t·∫•t c·∫£ c√°c c·ªôt t·ª´ stg_products")
        
        # Kh√¥ng c·∫ßn TRUNCATE v√¨ ƒë√£ DROP v√† t·∫°o l·∫°i b·∫£ng
        
        # L·∫•y danh s√°ch t·∫•t c·∫£ c√°c c·ªôt (tr·ª´ product_id v√¨ l√† AUTO_INCREMENT)
        # Lu√¥n escape t·∫•t c·∫£ t√™n c·ªôt v·ªõi backtick
        all_columns = [f"`{col[0]}`" for col in columns_info]
        columns_str = ', '.join(all_columns)
        
        # Insert to√†n b·ªô d·ªØ li·ªáu t·ª´ stg_products sang dim_product
        insert_sql = f"""
            INSERT INTO dim_product ({columns_str})
            SELECT {columns_str}
            FROM stg_products
        """
        
        result = conn.execute(text(insert_sql))
        inserted_count = result.rowcount
        
        # Th√™m UNIQUE constraint cho ten_san_pham n·∫øu ch∆∞a c√≥
        try:
            # Ki·ªÉm tra xem constraint ƒë√£ t·ªìn t·∫°i ch∆∞a
            check_constraint = conn.execute(text("""
                SELECT COUNT(*) 
                FROM INFORMATION_SCHEMA.TABLE_CONSTRAINTS 
                WHERE TABLE_SCHEMA = 'datawarehouse' 
                AND TABLE_NAME = 'dim_product' 
                AND CONSTRAINT_NAME = 'unique_product'
            """))
            
            if check_constraint.scalar() == 0:
                conn.execute(text("""
                    ALTER TABLE dim_product 
                    ADD UNIQUE KEY unique_product (ten_san_pham)
                """))
                print("   ‚úì ƒê√£ th√™m UNIQUE constraint cho ten_san_pham")
        except Exception as e:
            # N·∫øu constraint ƒë√£ t·ªìn t·∫°i ho·∫∑c c√≥ l·ªói, b·ªè qua
            print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ th√™m UNIQUE constraint: {e}")
    
    print(f" ‚úÖ ƒê√£ load {inserted_count} d√≤ng v√†o dim_product (to√†n b·ªô d·ªØ li·ªáu t·ª´ stg_products)")
    return inserted_count

# ============================================
# MAIN ETL PROCESS
# ============================================
def run_etl():
    print("B·∫ÆT ƒê·∫¶U QUY TR√åNH ETL: GENERAL ‚Üí STG_PRODUCTS ‚Üí DIM_PRODUCT")
    etl_id, batch_id = start_etl_log()
    try:
        df = extract_from_general()
        if len(df) == 0:
            print("  Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x·ª≠ l√Ω!")
            return
        df_clean = transform_data(df)
        inserted_stg = load_to_staging(df_clean)
        inserted_dim = load_to_dim()
        update_success_log(etl_id, inserted_stg)
        print("\nETL HO√ÄN T·∫§T TH√ÄNH C√îNG!")
        print(f"  ‚Ä¢ Batch ID: {batch_id}\n  ‚Ä¢ D√≤ng ƒë√£ x·ª≠ l√Ω (staging): {inserted_stg}\n  ‚Ä¢ D√≤ng n·∫°p v√†o dim: {inserted_dim}\n  ‚Ä¢ Tr·∫°ng th√°i: SUCCESS")
    except Exception as e:
        print("‚ùå ETL TH·∫§T B·∫†I!")
        print(f" L·ªói: {e}")
        update_error_log(etl_id, str(e))
        raise

# ============================================
# ENTRY POINT
# ============================================
if __name__ == "__main__":
    try:
        run_etl()
    except Exception as e:
        print(f"\nCh∆∞∆°ng tr√¨nh k·∫øt th√∫c v·ªõi l·ªói: {e}")
        exit(1)
